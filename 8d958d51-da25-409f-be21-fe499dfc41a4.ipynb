{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 15px; border: 3px solid indigo; padding: 15px;\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "Hi, I am a reviewer on this project. Congratulations on submitting another project! üéâ\n",
    "    \n",
    "\n",
    "Before we start, I want to pay your attention to the color marking:\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "\n",
    "Great solutions and ideas that can and should be used in the future are in green comments. Some of them are: \n",
    "    \n",
    "    \n",
    "- You have successfully read the data;\n",
    "    \n",
    "\n",
    "    \n",
    "- Used the correct way to encode categorical columns;    \n",
    "       \n",
    "    \n",
    "    \n",
    "- You have trained and compared several models, great!\n",
    "\n",
    "    \n",
    "    \n",
    "- Measured their training speed, good! \n",
    "\n",
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Yellow color indicates what should be optimized. This is not necessary, but it will be great if you make changes to this project. I've left several recommendations throughout the project. Please take a look.\n",
    " \n",
    "</div>\n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Issues that must be corrected to achieve accurate results are indicated in red comments. Please note that the project cannot be accepted until these issues are resolved. For instance,\n",
    "\n",
    "\n",
    "\n",
    "- Please try to explore the distributions and add conclusions; \n",
    "\n",
    "    \n",
    "    \n",
    "- Check the data for the duplicates after you drop columns. \n",
    "    \n",
    "    \n",
    "    \n",
    "- Please split the data first, only then we need to encode it.\n",
    "\n",
    "\n",
    "    \n",
    "- According to the task, we are supposed to measure models' prediction time as well. Would you update the code?\n",
    "\n",
    "\n",
    "    \n",
    "- Please add a conclusion about each model. How do they perform?\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "- We also need to tune hyperparameters. We tune them to identify the hyperparameters that will yield the desired metric value. Would you try to implement it?  \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- In the very end of the project, choose the best model (the one that yielded the best RMSE) and run the final test. \n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "- Add the final conclusion please. A well-written conclusion shows how the project met its objectives and provides a concise and understandable summary for those who may not have been involved in the details of the project. \n",
    "\n",
    "\n",
    "There may be other issues that need your attention. I described everything in my comments.  \n",
    "</div>        \n",
    "<hr>\n",
    "    \n",
    "<font color='dodgerblue'>**To sum up:**</font> you did a great job here, thank you so much! The updates should not take much time. If you have any questions, please feel free to ask. I will wait the project for the second review üòä \n",
    "    \n",
    "\n",
    "<hr>\n",
    "    \n",
    "Please use some color other than those listed to highlight answers to my comments.\n",
    "I would also ask you **not to change, move or delete my comments** to make it easier for me to navigate during the next review.\n",
    "    \n",
    "<hr> \n",
    "    \n",
    "‚úçÔ∏è Here's a link to [Supervised Learning documenation sections](https://scikit-learn.org/stable/supervised_learning.html) that you may find useful.\n",
    "    \n",
    "<hr>\n",
    "    \n",
    "    \n",
    "üìå Please feel free to schedule a 1:1 sessions with our tutors or TAs Feel free to book 1-1 session [here](https://calendly.com/tripleten-ds-experts-team), join daily coworking sessions, or ask questions in the sprint channels on Discord if you need assistance üòâ \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. You have access to historical data: technical specifications, trim versions, and prices. You need to build the model to determine the value. \n",
    "\n",
    "Rusty Bargain is interested in:\n",
    "\n",
    "- the quality of the prediction;\n",
    "- the speed of the prediction;\n",
    "- the time required for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>   Reviewer's comment </h2>\n",
    "    \n",
    "Good introduction! \n",
    "    \n",
    "</div>\n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2>   Reviewer's comment </h2>\n",
    "    \n",
    "Please don't forget about project title :) A title should reflect the core goals.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "data = pd.read_csv('/datasets/car_data.csv')\n",
    "\n",
    "data = data.drop(columns=['NumberOfPictures', 'PostalCode'])\n",
    "\n",
    "categorical_features = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']\n",
    "for col in categorical_features:\n",
    "    data[col] = data[col].fillna('unknown')\n",
    "\n",
    "data = data[(data['RegistrationYear'] >= 1900) & (data['RegistrationYear'] <= 2023)]\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "target = data['Price']\n",
    "features = data.drop(columns=['Price'])\n",
    "\n",
    "features_full_train, features_test, target_full_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345)\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_full_train, target_full_train, test_size=0.25, random_state=12345)\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "ohe.fit(features_train[categorical_features])\n",
    "\n",
    "def encode(df):\n",
    "    encoded = pd.DataFrame(ohe.transform(df[categorical_features]), index=df.index)\n",
    "    encoded.columns = ohe.get_feature_names(categorical_features)\n",
    "    df = df.drop(columns=categorical_features).reset_index(drop=True)\n",
    "    encoded = encoded.reset_index(drop=True)\n",
    "    return pd.concat([df, encoded], axis=1)\n",
    "\n",
    "features_train = encode(features_train)\n",
    "features_valid = encode(features_valid)\n",
    "features_test = encode(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment </h2>\n",
    "    \n",
    "Great choice! `OneHotEncoder(handle_unknown='ignore')` or `OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)` are generally more robust than `get_dummies` because they can handle situations where test subset has features that were not available during training. [Difference between OneHotEncoder and get_dummies](https://pythonsimplified.com/difference-between-onehotencoder-and-get_dummies/). \n",
    "    \n",
    "    \n",
    "    \n",
    "For tree-based models, `OrdinalEncoder` is a better choice because of computational cost. For boosting algorithms, we can rely on internal encoders that usually perform even better than external ones. For `CatBoost`, this is controlled by the `cat_features` parameter. For `LightGBM`, you can convert categorical features to the category type, allowing the model to handle them automatically.\n",
    "    \n",
    "    \n",
    "    \n",
    "Please note that `OrdinalEncoder()` should not be used with linear models if there's no ordinal relationship. [How and When to Use Ordinal Encoder](https://leochoi146.medium.com/how-and-when-to-use-ordinal-encoder-d8b0ef90c28c).\n",
    "\n",
    "\n",
    "</div><div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment </h2>\n",
    "    \n",
    "- Let's not drop so many rows :) Instead, replace missing values with some unique row, such as \"Unknown\". \n",
    "\n",
    "\n",
    "\n",
    "- Are there any outliers in the data?  Please call the `describe` method and display charts. Drop abnormal values if they exist. \n",
    "\n",
    "\n",
    "\n",
    "- Please check max dates in the `RegistrationYear` and  `DateCrawled` columns. Vehicle should not be registered after the data was downloaded :) \n",
    "\n",
    "\n",
    "\n",
    "- There are other columns that can be dropped. After removing unnecessary columns, it makes sense to check the data for duplicates again, as the dataset will later be splitted into training and test sets. Removing specific columns can cause previously distinct rows to become identical. If a dropped column contained unique values (ID or timestamp), removing it may make multiple rows appear the same.   \n",
    "\n",
    "\n",
    "\n",
    "- We should encode data after we split it to avoid data leakage. Would you fix it please? </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, name):\n",
    "    start_time = time.time()\n",
    "    model.fit(features_train, target_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    predictions = model.predict(features_valid)\n",
    "    rmse = mean_squared_error(target_valid, predictions, squared=False)\n",
    "    \n",
    "    print(f\"{name} - RMSE: {rmse:.2f}, Training time: {train_time:.2f} sec\")\n",
    "    del model  # Clear model from memory after training\n",
    "    gc.collect()  # Force garbage collection to free up memory\n",
    "\n",
    "# Set up your models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=12345),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=12345),\n",
    "    \"LightGBM\": LGBMRegressor(n_estimators=10, random_state=12345)  # Reduce n_estimators for testing\n",
    "}\n",
    "\n",
    "# Make sure to only call models after you finish preprocessing\n",
    "for name, model in models.items():\n",
    "    train_and_evaluate(model, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment </h2>\n",
    "    \n",
    "Well done! \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Performance Summary:\")\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(features_train, target_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    predictions = model.predict(features_valid)\n",
    "    rmse = mean_squared_error(target_valid, predictions, squared=False)\n",
    "    print(f\"{name}: RMSE = {rmse:.2f}, Training time: {train_time:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment </h2>\n",
    "    \n",
    "Good! I'll run your code on my local machine, since the kernel here cannot handle heavy projects. \n",
    "\n",
    "</div>\n",
    "<div class=\"alert alert-warning\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment </h2>\n",
    "    \n",
    "You can use the function you defined above.\n",
    "\n",
    "</div>\n",
    "<div class=\"alert alert-danger\" style=\"border-radius: 15px; box-shadow: 4px 4px 4px; border: 1px solid \">\n",
    "<h2> Reviewer's comment </h2>\n",
    "    \n",
    "- According to the task, we also need to estimate the prediction time. Would you try?\n",
    "\n",
    "\n",
    "- Please try to tune hyperparameters for at least one of the models. If you decide to use a loop, don't forget to change the way you split the data, because in this case we will need three subsets, not two. \n",
    "    \n",
    "    \n",
    "- It will be perfect if you add a conclusion about each model. How do they perform?\n",
    "\n",
    "    \n",
    "- After you train all models, please choose the best one and check its performance on the test subset. \\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Let's add the overall conclusion to your project: what has been done and what can be inferred from the results. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 'x' to check. Then press Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [ ]  Code is error free\n",
    "- [ ]  The cells with the code have been arranged in order of execution\n",
    "- [ ]  The data has been downloaded and prepared\n",
    "- [ ]  The models have been trained\n",
    "- [ ]  The analysis of speed and quality of the models has been performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  hey if the code has an error im sorry but i keep getting a dead kernal \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 847,
    "start_time": "2025-04-03T12:21:43.237Z"
   },
   {
    "duration": 847,
    "start_time": "2025-04-03T12:21:44.086Z"
   },
   {
    "duration": 0,
    "start_time": "2025-04-03T12:21:44.935Z"
   },
   {
    "duration": 0,
    "start_time": "2025-04-03T12:21:44.936Z"
   },
   {
    "duration": 4,
    "start_time": "2025-04-03T12:22:58.416Z"
   },
   {
    "duration": 1087,
    "start_time": "2025-04-03T12:22:58.422Z"
   },
   {
    "duration": 0,
    "start_time": "2025-04-03T12:22:59.511Z"
   },
   {
    "duration": 0,
    "start_time": "2025-04-03T12:22:59.512Z"
   },
   {
    "duration": 551,
    "start_time": "2025-04-03T12:23:42.072Z"
   },
   {
    "duration": 6,
    "start_time": "2025-04-03T12:25:54.277Z"
   },
   {
    "duration": 1169,
    "start_time": "2025-04-03T12:25:54.817Z"
   },
   {
    "duration": 1980,
    "start_time": "2025-04-03T12:26:49.686Z"
   },
   {
    "duration": 856,
    "start_time": "2025-04-03T12:27:04.826Z"
   },
   {
    "duration": 1984,
    "start_time": "2025-04-03T12:27:05.684Z"
   },
   {
    "duration": 825,
    "start_time": "2025-04-03T12:27:20.165Z"
   },
   {
    "duration": 2011,
    "start_time": "2025-04-03T12:27:20.992Z"
   },
   {
    "duration": 811,
    "start_time": "2025-04-03T12:27:46.365Z"
   },
   {
    "duration": 2036,
    "start_time": "2025-04-03T12:27:47.180Z"
   },
   {
    "duration": 838,
    "start_time": "2025-04-03T12:38:48.451Z"
   },
   {
    "duration": 2004,
    "start_time": "2025-04-03T12:38:50.473Z"
   },
   {
    "duration": 159,
    "start_time": "2025-04-03T12:39:46.703Z"
   },
   {
    "duration": 811,
    "start_time": "2025-04-03T12:43:59.455Z"
   },
   {
    "duration": 1996,
    "start_time": "2025-04-03T12:44:00.268Z"
   },
   {
    "duration": 160,
    "start_time": "2025-04-03T12:44:43.562Z"
   },
   {
    "duration": 819,
    "start_time": "2025-04-03T12:44:46.408Z"
   },
   {
    "duration": 2029,
    "start_time": "2025-04-03T12:44:47.231Z"
   },
   {
    "duration": 161,
    "start_time": "2025-04-03T12:44:53.859Z"
   },
   {
    "duration": 14,
    "start_time": "2025-04-03T12:45:56.942Z"
   },
   {
    "duration": 811,
    "start_time": "2025-04-03T12:46:00.567Z"
   },
   {
    "duration": 2006,
    "start_time": "2025-04-03T12:46:01.380Z"
   },
   {
    "duration": 842,
    "start_time": "2025-04-03T12:46:10.540Z"
   },
   {
    "duration": 1985,
    "start_time": "2025-04-03T12:46:11.384Z"
   },
   {
    "duration": 164,
    "start_time": "2025-04-03T12:46:39.770Z"
   },
   {
    "duration": 1072,
    "start_time": "2025-04-04T02:37:16.800Z"
   },
   {
    "duration": 3032,
    "start_time": "2025-04-04T02:37:18.989Z"
   },
   {
    "duration": 2825,
    "start_time": "2025-04-07T14:58:09.002Z"
   },
   {
    "duration": 82,
    "start_time": "2025-04-07T14:58:16.639Z"
   },
   {
    "duration": 2010,
    "start_time": "2025-04-07T14:58:16.805Z"
   },
   {
    "duration": 2429,
    "start_time": "2025-04-07T15:09:35.422Z"
   },
   {
    "duration": 4,
    "start_time": "2025-04-07T15:10:06.361Z"
   },
   {
    "duration": 2448,
    "start_time": "2025-04-07T15:10:06.508Z"
   },
   {
    "duration": 253,
    "start_time": "2025-04-07T15:13:23.313Z"
   },
   {
    "duration": 872,
    "start_time": "2025-04-07T15:24:22.109Z"
   },
   {
    "duration": 2561,
    "start_time": "2025-04-07T15:24:22.984Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
